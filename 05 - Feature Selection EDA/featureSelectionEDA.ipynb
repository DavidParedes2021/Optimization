{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection con EDA\n",
    "## David Omar Paredes Paredes\n",
    "## Abraham Maximiliano Ávalos Corrales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy             as np\n",
    "import pandas            as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model    import LinearRegression\n",
    "from sklearn.metrics         import mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25 1.   0.75 0.5 ]\n"
     ]
    }
   ],
   "source": [
    "pop = np.array(\n",
    "\t[[0, 1, 1, 0]\n",
    "\t,[0, 1, 0, 1]\n",
    "\t,[1, 1, 1, 1]\n",
    "\t,[0, 1, 1, 0]\n",
    "\t]\n",
    ")\n",
    "\n",
    "prob = np.count_nonzero(pop, axis=0) / len(pop[0])\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clases de utilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Problem:\n",
    "\tdef generate_initial_population(self, p_size) -> list:...\n",
    "\tdef _compare(self, fitness_a, fitness_b) -> int:...\n",
    "\n",
    "\tdef get_parent(self, parent_F:list) -> int:...\n",
    "\tdef mix_parents(self, parent_a, parent_b, ratio:float=0.5):...\n",
    "\tdef mutate(self, g):...\n",
    "\tdef check_individual_integrity(self, g) -> bool: return True\n",
    "\t\t\n",
    "\tdef get_prob_dist(self, E:list):...\n",
    "\tdef generate_from_prob_dist(self, Pd:list, n_p:int) -> list:...\n",
    "\n",
    "\tdef get_fitness(self, G:list, F:list=None):...\n",
    "\tdef get_elite(self, G:list, F:list) -> (list, list):...\n",
    "\tdef arg_get_elite(self, G:list, F:list, n:int=1):...\n",
    "\tdef deep_copy(self, G, population:bool=True):...\n",
    "\tdef update_elite(self, E, newE, Fe, newFe):...\n",
    "\n",
    "\tdef solved(self, Fe:list): return False\n",
    "\tdef has_progress_metric(self) -> bool: return False\n",
    "\tdef get_progress_metric(self, F:list) -> float:...\n",
    "\tdef get_progress_max(self) -> float:...\n",
    "\tdef get_variation(self, F:list) -> float:...\n",
    "\tdef custom_print(self, G:list, F:list):...\n",
    "\n",
    "class Feature_selection(Problem):\n",
    "\tdef __init__(self, filename:str, model=LinearRegression):\n",
    "\t\tself.filename       = filename\n",
    "\t\tself.df             = pd.read_csv(filename)\n",
    "\t\tself.num_features   = self.df.shape[1] -1\n",
    "\t\tself.features_names = self.df.columns[:-1]\n",
    "\t\tself.target_name    = self.df.columns[-1]\n",
    "\t\tself.rng            = np.random.default_rng()\n",
    "\n",
    "\t\tself.model = model\n",
    "\n",
    "\tdef generate_initial_population(self, p_size) -> list:\n",
    "\t\tG = np.random.choice([False, True], size=(p_size, self.num_features))\n",
    "\t\tG[0] = np.full((1, self.num_features), True) # 1 with all features\n",
    "\t\treturn G\n",
    "\n",
    "\tdef _compare(self, fitness_a, fitness_b):\n",
    "\t\t# if a dominates b, return will be 1, -1 if the contrary\n",
    "\t\t# if there is no dominance, 0 will be returned\n",
    "\t\tif fitness_a[1] - fitness_b[1] == 0.0:\n",
    "\t\t\tif fitness_a[0] < fitness_b[0]:\n",
    "\t\t\t\treturn 1\n",
    "\t\t\treturn -1\n",
    "\t\ttry:\n",
    "\t\t\tm = (fitness_a[0] - fitness_b[0]) / (fitness_a[1] - fitness_b[1])\n",
    "\t\texcept ZeroDivisionError:\n",
    "\t\t\treturn 0\n",
    "\t\tif m > 0:\n",
    "\t\t\tif fitness_a[0] < fitness_b[0]:\n",
    "\t\t\t\treturn 1\n",
    "\t\t\treturn -1\n",
    "\t\treturn 0\n",
    "\n",
    "\tdef get_parent(self, parent_F:list, parent_G:list=None, parent_idx:list=None):\n",
    "\t\tn = len(parent_F)  # Assuming n is the length of the parent_F list\n",
    "\t\tparent_candidates_idx = np.random.randint(0, n, 2)\n",
    "\t\tmin_value = float('inf')\n",
    "\t\tmin_index = None\n",
    "\t\t\n",
    "\t\tfor idx in parent_candidates_idx:\n",
    "\t\t\tif parent_F[idx][2] < min_value:\n",
    "\t\t\t\tmin_value = parent_F[idx][2]\n",
    "\t\t\t\tmin_index = idx\n",
    "\t\t\n",
    "\t\treturn min_index\n",
    "\n",
    "\tdef mix_parents(self, parent_a, parent_b, ratio:float=0.5, get_indexes=False):\n",
    "\t\tgenotype_len = len(parent_a)\n",
    "\n",
    "\t\ta_idxs = set()\n",
    "\t\tacum = 0\n",
    "\t\tfor i in range(genotype_len):\n",
    "\t\t\tacum += ratio\n",
    "\t\t\tif acum >= 1:\n",
    "\t\t\t\tacum -= 1\n",
    "\t\t\t\ta_idxs.add(i)\n",
    "\t\tb_idxs = {i for i in range(genotype_len)} - a_idxs\n",
    "\n",
    "\t\ta_idxs = list(a_idxs)\n",
    "\t\tb_idxs = list(b_idxs)\n",
    "\t\tchild  = np.zeros((genotype_len), bool)\n",
    "\n",
    "\t\tchild[a_idxs] = parent_a[a_idxs].copy()\n",
    "\t\tchild[b_idxs] = parent_b[b_idxs].copy()\n",
    "\t\tif get_indexes:\n",
    "\t\t\treturn child, (a_idxs, b_idxs)\n",
    "\t\treturn child\n",
    "\n",
    "\tdef mutate(self, g):\n",
    "\t\tgen = g.copy()\n",
    "\t\trand = random.randint(0, len(gen) - 1)\n",
    "\t\tgen[rand] = not gen[rand]\n",
    "\t\treturn gen\n",
    "\tdef check_individual_integrity(self, g) -> bool:\n",
    "\t\tn_features = np.count_nonzero(g)\n",
    "\t\treturn n_features > 0\n",
    "\t\n",
    "\tdef get_prob_dist(self, E:list):\n",
    "\t\tp_dist = prob = np.count_nonzero(E, axis=0) / len(E)\n",
    "\t\treturn p_dist\n",
    "\t#----- end get_prob_dist\n",
    "\tdef generate_from_prob_dist(self, Pd:list, n_p:int) -> list:\n",
    "\t\tnew_p = np.zeros((n_p, self.num_features), dtype=bool)\n",
    "\t\tI, J = new_p.shape\n",
    "\t\tfor i in range(I):\n",
    "\t\t\tfor j in range(J):\n",
    "\t\t\t\tif self.rng.random() < Pd[j]:\n",
    "\t\t\t\t\tnew_p[i,j] = True\n",
    "\t\treturn new_p\n",
    "\t#----- end generate_from_prob_dist\n",
    "\n",
    "\tdef NSGA2(self, fitness):\n",
    "\t\tn = len(fitness)\n",
    "\t\tlevels = np.zeros(n)\n",
    "\t\tdominates = [[] for _ in range(n)]\n",
    "\t\t#dd =  [[] for _ in range(n)]\n",
    "\t\tis_dominated_by = {}\n",
    "\t\tfor i in range(n):\n",
    "\t\t\tis_dominated_by[i] = 0\n",
    "\t\tfor idx_first_point, first_point in enumerate(fitness):\n",
    "\t\t\tfor idx_second_point in range(idx_first_point+1, len(fitness)):\n",
    "\t\t\t\tsecond_point = fitness[idx_second_point]\n",
    "\t\t\t\tm = self._compare(first_point, second_point)\n",
    "\t\t\t\tif m == 1: #first_point dominates\n",
    "\t\t\t\t\tis_dominated_by[idx_second_point] +=1\n",
    "\t\t\t\t\tdominates[idx_first_point].append(idx_second_point)\n",
    "\t\t\t\t\t#dd[idx_second_point].append(idx_first_point)\n",
    "\t\t\t\telif m == -1:\n",
    "\t\t\t\t\tis_dominated_by[idx_first_point] +=1\n",
    "\t\t\t\t\tdominates[idx_second_point].append(idx_first_point)\n",
    "\t\t\t\t\t#dd[idx_first_point].append(idx_second_point)\n",
    "\t\t#for bbb,pp in enumerate(dd):\n",
    "\t\t\t#   print(bbb,pp)\n",
    "\n",
    "\t\tcurr_level = 0\n",
    "\t\twhile len(is_dominated_by) > 0:\n",
    "\t\t\tnon_dominated_indices = [idx for idx, dominance_count in is_dominated_by.items() if dominance_count == 0]\n",
    "\n",
    "\t\t\tfor idx in non_dominated_indices:\n",
    "\t\t\t\tfor dominated_idx in dominates[idx]:\n",
    "\t\t\t\t\tis_dominated_by[dominated_idx] -= 1\n",
    "\n",
    "\t\t\t\tlevels[idx] = curr_level\n",
    "\t\t\t\tdel is_dominated_by[idx]\n",
    "\t\t\tcurr_level+=1\n",
    "\t\t\t\t\n",
    "\t\treturn levels\n",
    "\t\t\n",
    "\tdef get_fitness(self, G:list, F:list=None):\n",
    "\t\tfitness = []\n",
    "\t\tfor gi in G:\n",
    "\t\t\tselected_features = self.features_names[gi]\n",
    "\n",
    "\t\t\t# Prepare the data\n",
    "\t\t\tX = self.df[selected_features]\n",
    "\t\t\ty = self.df[self.target_name]\n",
    "\n",
    "\t\t\t# Split the data into training and testing sets\n",
    "\t\t\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=20)\n",
    "\n",
    "\t\t\t# Initialize and train the linear regression model\n",
    "\t\t\tmodel = self.model()\n",
    "\t\t\tmodel.fit(X_train, y_train)\n",
    "\n",
    "\t\t\t# Make predictions\n",
    "\t\t\ty_pred = model.predict(X_test)\n",
    "\n",
    "\t\t\t# Metrics\n",
    "\t\t\tmae = mean_absolute_error(y_test, y_pred)\n",
    "\t\t\tn_features_used = np.count_nonzero(gi)\n",
    "\t\t\tfitness.append([mae,n_features_used/self.num_features])\n",
    "\t\t\n",
    "\t\tlevels = self.NSGA2(fitness)\n",
    "\t\tfitness_w_levels = [point + [lvl] for point, lvl in zip(fitness, levels)]\n",
    "\t\t\n",
    "\t\t#for fidx,fitn in enumerate(fitness_w_levels):\n",
    "\t\t#    print(fidx,\": \",fitn)\n",
    "\t\t#print(\"levels:\",levels)\n",
    "\t\t#graphicate_points(fitness)\n",
    "\t\treturn np.array(fitness_w_levels)\n",
    "\n",
    "\tdef update_elite(self, E, newE, Fe, newFe):\n",
    "\t\tnew_elite_fitness = []\n",
    "\t\tnew_elite_string = []\n",
    "\t\tfor idx, e in enumerate(Fe):\n",
    "\t\t\tnew_elite_fitness.append(e.copy())\n",
    "\t\t\tnew_elite_string.append(E[idx].copy())\n",
    "\t\tfor idx, e in enumerate(newFe):\n",
    "\t\t\tnew_elite_fitness.append(e.copy())\n",
    "\t\t\tnew_elite_string.append(newE[idx].copy())\n",
    "\t\t\n",
    "\t\tlevels = self.NSGA2(new_elite_fitness)\n",
    "\t\t\n",
    "\t\tfor idx, e in enumerate(new_elite_fitness):\n",
    "\t\t\te[2] = levels[idx]\n",
    "\t\treturn self.get_elite(new_elite_string, new_elite_fitness)\n",
    "\n",
    "\tdef get_elite(self, G:list, F:list) -> (list, list):\n",
    "\t\telites_fitness = []\n",
    "\t\telites_string = []\n",
    "\t\tfor idx, fitn in enumerate(F):\n",
    "\t\t\tif fitn[2]==0:\n",
    "\t\t\t\telites_fitness.append(fitn.copy())\n",
    "\t\t\t\telites_string.append(G[idx].copy())\n",
    "\t\treturn elites_string, elites_fitness\n",
    "\t\n",
    "\tdef arg_get_elite(self, G:list, F:list, n:int=1):\n",
    "\t\tbest = np.argsort(F[:,2])\n",
    "\t\tif n==1: return best[0]\n",
    "\t\telse:    return best[:n]\n",
    "\t#----- end arg_get_elite\n",
    "\n",
    "\tdef deep_copy(self, G, population:bool=True):\n",
    "\t\tif population:\n",
    "\t\t\treturn [g.copy() for g in G]\n",
    "\t\telse:\n",
    "\t\t\treturn G.copy()\n",
    "\tdef is_elite_list(self) -> bool:\n",
    "\t\treturn True\n",
    "\n",
    "\tdef solved(self, Fe:list):\n",
    "\t\treturn False\n",
    "\tdef has_progress_metric(self) -> bool:\n",
    "\t\treturn True\n",
    "\tdef get_progress_metric(self, F:list) -> float:\n",
    "\t\tdiag      = [1, 1]\n",
    "\t\tdiag_norm = np.linalg.norm(diag)\n",
    "\t\tslope = [np.dot(f[:-1], diag) / (np.linalg.norm(f[:-1])*diag_norm)  for f in F]\n",
    "\t\treturn 1 - np.min(slope)\n",
    "\tdef get_progress_max(self) -> float:\n",
    "\t\treturn 1\n",
    "\tdef get_variation(self, F:list) -> float:\n",
    "\t\tdiag      = [1, 1]\n",
    "\t\tdiag_norm = np.linalg.norm(diag)\n",
    "\t\tslope = [np.dot(f[:-1], diag) / (np.linalg.norm(f[:-1])*diag_norm)  for f in F]\n",
    "\t\treturn np.std(slope)\n",
    "\tdef custom_print(self, G:list, F:list):\n",
    "\t\t# Set smaller figure size\n",
    "\t\tplt.figure(figsize=(5, 5))  # Adjust the width and height as needed\n",
    "\n",
    "\t\t# Plot the points\n",
    "\t\tfor i, point in enumerate(F):\n",
    "\t\t\t\tplt.scatter(point[0], point[1], color='blue', s=50)  # Reduced marker size\n",
    "\t\t\t\tplt.text(point[0], point[1], str(i), fontsize=8, ha='center', va='bottom')\n",
    "\n",
    "\t\tplt.xlabel('X-axis')\n",
    "\t\tplt.ylabel('Y-axis')\n",
    "\t\tplt.title('Plot')\n",
    "\n",
    "\t\t# Set axis limits\n",
    "\t\tplt.xlim(0.4, 1)\n",
    "\t\tplt.ylim(0, 1)\n",
    "\n",
    "\t\t# Add grid\n",
    "\t\tplt.grid(True)\n",
    "\t\tplt.tight_layout()  # Ensure proper spacing\n",
    "\t\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True  True  True  True  True  True  True  True  True]\n",
      " [False False False False False  True  True  True False  True False]\n",
      " [False False  True False False  True  True False  True False False]\n",
      " [ True False False False False False  True  True  True  True False]\n",
      " [ True  True False False  True  True  True False False False  True]\n",
      " [False False False False False  True False  True False  True False]\n",
      " [ True  True  True  True  True False  True False  True False  True]\n",
      " [False False False False False False False False  True  True False]\n",
      " [False  True  True  True False  True False  True False  True False]\n",
      " [ True False  True False False  True  True  True False False False]]\n",
      "---------------\n",
      "[[0.48281927 1.         0.        ]\n",
      " [0.57735309 0.36363636 0.        ]\n",
      " [0.49252673 0.54545455 0.        ]\n",
      " [0.61406324 0.27272727 0.        ]]\n",
      "---------------\n",
      "[[ True  True  True  True  True  True  True  True  True  True  True]\n",
      " [False False  True False False  True  True False  True False False]\n",
      " [ True  True False False  True  True  True False False False  True]\n",
      " [False False False False False  True False  True False  True False]]\n",
      "---------------\n",
      "[0.5  0.5  0.5  0.25 0.5  1.   0.75 0.5  0.5  0.5  0.5 ]\n",
      "---------------\n",
      "[[False  True False False False  True  True False False False  True]\n",
      " [False  True False  True False  True False  True False False  True]\n",
      " [False  True False  True False  True False  True  True  True  True]\n",
      " [False False False False  True  True  True False  True  True  True]\n",
      " [False  True  True False  True  True  True  True  True  True  True]\n",
      " [ True  True False False False  True  True  True False False  True]\n",
      " [False False  True False  True  True  True False False  True False]\n",
      " [False  True False False  True  True  True False  True False  True]\n",
      " [ True False False False  True  True  True False  True False  True]\n",
      " [ True False  True False  True  True  True False False False  True]]\n",
      "---------------\n",
      "[0.3 0.6 0.3 0.2 0.6 1.  0.8 0.4 0.5 0.4 0.9]\n"
     ]
    }
   ],
   "source": [
    "\t# def get_prob_dist(self, E:list):...\n",
    "\t# def generate_from_prob_dist(self, Pd:list, n_p:int) -> list:...\n",
    "\n",
    "problem = Feature_selection('wine.csv')\n",
    "pop     = problem.generate_initial_population(10)\n",
    "fit     = problem.get_fitness(pop)\n",
    "elite_i = problem.arg_get_elite(pop, fit, n=4)\n",
    "dist    = problem.get_prob_dist(pop[elite_i])\n",
    "npop    = problem.generate_from_prob_dist(dist, 10)\n",
    "ndist   = problem.get_prob_dist(npop)\n",
    "print(pop,         end='\\n---------------\\n')\n",
    "print(fit[elite_i],end='\\n---------------\\n')\n",
    "print(pop[elite_i],end='\\n---------------\\n')\n",
    "print(dist,        end='\\n---------------\\n')\n",
    "print(npop,        end='\\n---------------\\n')\n",
    "print(ndist)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
